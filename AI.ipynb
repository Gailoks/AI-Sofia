{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import numpy as np\n",
    "import Tokens as tk\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "VOCAB_SIZE = 1201"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "разбивка текста и создание словаря"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "samples = []\n",
    "for sample in os.listdir('samples'):\n",
    "    with open(\"samples/\" + sample, encoding=\"utf-8\") as text:\n",
    "        samples.append(text.read().lower())\n",
    "\n",
    "\n",
    "class QAPair:\n",
    "    def __init__(self, question, answer):\n",
    "        self.question = question\n",
    "        self.answer = answer\n",
    "\n",
    "dataset = []\n",
    "\n",
    "for sample in samples:\n",
    "    lines = sample.splitlines()\n",
    "    questions = lines[::2]\n",
    "    answers = lines[1::2]\n",
    "    for q, a in zip(questions, answers):\n",
    "        dataset.append(QAPair(q, a))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdg = tk.TokenDictionaryGenerator(vocabulary_size = VOCAB_SIZE-1)\n",
    "tokens = tdg.generate_tokens(samples)\n",
    "tokenizer = tk.Tokenizer(tokens)\n",
    "tokens.save(\"tokens.json\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "создание модели \n",
    "предложение -> hidden\n",
    "последние слово + hidden -> слово(1)...слово(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RnnTextGen(nn.Module):\n",
    "\n",
    "    def __init__(self,input_size,inp_lstm_size,hid_size,n_layers,out_size,dropout=0.2) -> None:\n",
    "        super(RnnTextGen,self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.out_size = out_size\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size=hid_size\n",
    "        self.Encoder = nn.Embedding(input_size,inp_lstm_size)\n",
    "        self.lstm = nn.LSTM(inp_lstm_size,hid_size,n_layers)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.l1 = nn.Linear(hid_size,out_size)\n",
    "        self.l2 = nn.Linear(inp_lstm_size,out_size)\n",
    "        self.attention = nn.MultiheadAttention(out_size,1)\n",
    "        \n",
    "    def forward(self,x,hidden=None):\n",
    "        x = self.Encoder(x)\n",
    "        p = self.l2(x)\n",
    "        aw,_ = self.attention(p.view(-1,self.out_size),p.view(-1,self.out_size),p.view(-1,self.out_size))#a - attn output b - attn_wheights)\n",
    "        x,hidden = self.lstm(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.l1(x)\n",
    "        x = torch.cat((aw,x))\n",
    "        return x,hidden\n",
    "    \n",
    "    def init_hidden(self,batch_size=1):\n",
    "        return (torch.zeros(self.n_layers, batch_size, self.hidden_size, requires_grad=True).to(device),\n",
    "               torch.zeros(self.n_layers, batch_size, self.hidden_size, requires_grad=True).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=RnnTextGen(VOCAB_SIZE-1,1000,500,2,VOCAB_SIZE).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2, amsgrad=True)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, \n",
    "    patience=5, \n",
    "    verbose=True, \n",
    "    factor=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1201])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch.LongTensor([1,2]).to(device))[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model:RnnTextGen,text:str,prediction_lim:int=15):\n",
    "    text_idx = torch.LongTensor(list(tokenizer.tokenize(text))).to(device)\n",
    "    hidden = model.init_hidden()\n",
    "    inp = text_idx\n",
    "    predicted_text=\"\"\n",
    "    for i in range(prediction_lim):\n",
    "        next_w , hidden = model(inp.to(device),hidden)\n",
    "        inp = torch.cat([inp,next_w[-1].argmax().view(-1)])\n",
    "        if next_w[-1].argmax() == torch.LongTensor([VOCAB_SIZE-1]).to(device):\n",
    "            break\n",
    "        word = tokens.decode(int(next_w[-1].argmax()))\n",
    "        predicted_text +=word\n",
    "    return predicted_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(dataset:list):\n",
    "    for qa in dataset:\n",
    "        question_idx = list(tokenizer.tokenize(qa.question))\n",
    "        target = list(tokenizer.tokenize(qa.answer))+[tokens.count()]\n",
    "        test = question_idx+target[:-1]\n",
    "\n",
    "        target =torch.LongTensor(target).to(device)\n",
    "        test = torch.LongTensor(test).to(device)\n",
    "        yield target,test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoches:int,model:RnnTextGen,batch_size:int)->None:\n",
    "    \"\"\"epoches - number of epoches through all dataset\n",
    "    model - model required to teach\n",
    "    batch_size - n/a\"\"\"\n",
    "    loss_avg =[]\n",
    "    for epoch in range(epoches):\n",
    "        for target,train in get_batch(dataset):\n",
    "            model.train()\n",
    "\n",
    "            hidden = model.init_hidden(batch_size)\n",
    "\n",
    "            output,hidden = model(train,hidden)\n",
    "            target_len = len(target)\n",
    "            loss = criterion(output[-target_len:],target)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            loss_avg.append(loss.item())\n",
    "            if len(loss_avg) >= 50:\n",
    "                mean_loss = np.mean(loss_avg)\n",
    "                print(f'Loss: {mean_loss}')\n",
    "                scheduler.step(mean_loss)\n",
    "                model.eval()\n",
    "                question = random.choice(dataset).question\n",
    "                answer = evaluate(model,question)\n",
    "                print(f\"Question: {question} \\n Answer: {answer}\")\n",
    "                loss_avg = []"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 6.634598226547241\n",
      "Question: какой твой любимый домашний питомец? \n",
      " Answer: я дум.\n",
      "Loss: 6.571789798736572\n",
      "Question: я буду использовать базу даных наших собщений \n",
      " Answer: , это , это , это , это , это , это , это ,\n",
      "Loss: 5.8139488697052\n",
      "Question: знаешь, в последнее время я интересуюсь фотографией. мне нравится фиксировать моменты и сохранять их на фото. \n",
      " Answer: \n",
      "Loss: 6.056747531890869\n",
      "Question: и как мы можем знать, что предопределено, а что нет? \n",
      " Answer: \n",
      "Loss: 5.445373315811157\n",
      "Question: какую роль играет учитель в образовании? \n",
      " Answer: мы можем сделать,,ей ей ей знамой,, но .\n",
      "Loss: 5.521321187019348\n",
      "Question: но как мы можем получить практический опыт? \n",
      " Answer: \n",
      "Loss: 5.168804602622986\n",
      "Question: но как мы можем получить практический опыт? \n",
      " Answer: мы можем олучисти,ну,нф призв,ходяакже \n",
      "Loss: 4.643971447944641\n",
      "Question: какой твой любимый музыкальный жанр? \n",
      " Answer: \n",
      "Loss: 4.664632339477539\n",
      "Question: привет как я могу тебя звать? \n",
      " Answer: мы можем получить информациции, чтоони\n",
      "Loss: 3.7538588786125184\n",
      "Question: как важен практический опыт в образовании? \n",
      " Answer: \n",
      "Loss: 3.661936640739441\n",
      "Question: каково значение человеческой жизни? \n",
      " Answer: мы можем получить информацию о различных профессия\n",
      "Loss: 3.4041370332241057\n",
      "Question: как тебя зовут? \n",
      " Answer: \n",
      "Loss: 3.1782702362537383\n",
      "Question: перечисли твои любимые цвета \n",
      " Answer: мои любимые цвета: желтый, рабыед\n",
      "Loss: 2.639802723005414\n",
      "Question: да, я согласен. ведь это помогает ученикам сохранять мотивацию учиться и добиваться успеха. \n",
      " Answer:  а ты?\n",
      "Loss: 2.757638154476881\n",
      "Question: какой твой любимый цвет? \n",
      " Answer: мой любимый цвет розовый\n",
      "Loss: 1.875942492298782\n",
      "Question: кст нам так и не дали 200 рублей \n",
      " Answer: е\n",
      "Loss: 2.0563232405483722\n",
      "Question: какую роль играет учитель в образовании? \n",
      " Answer: мы можем получить информацию о различных профессия\n",
      "Loss: 1.382330086864531\n",
      "Question: как называется животное, которое может прыгать на большие расстояния? \n",
      " Answer: животное, которое может прылект который помогает \n",
      "Loss: 1.6275054804980755\n",
      "Question: но как мы можем определить, что правильно, а что нет? \n",
      " Answer: это может быть сложно, но я думаю, что кажда\n",
      "Loss: 1.1010899684391915\n",
      "Question: как тебя зовут? \n",
      " Answer: меня зовут софия я искусттвенный интелект при\n",
      "Loss: 1.2408571473509074\n",
      "Question: как дела у синего? \n",
      " Answer: у меня в ри любищей цельуте упность и ка\n",
      "Loss: 0.7369444076763466\n",
      "Question: но как мы можем узнать истину? \n",
      " Answer: мы можем использовать новые технологии, которая не умеет \n",
      "Loss: 0.925454127639532\n",
      "Question: как новые технологии могут помочь в образовании? \n",
      " Answer: новые техноонтерских программах.\n",
      "Loss: 0.5087519098259509\n",
      "Question: как дела у синего? \n",
      " Answer: у меня в римворлде с таким именем \n",
      "Loss: 0.6642940675280988\n",
      "Question: как новые технологии могут помочь в образовании? \n",
      " Answer: новые техно.\n",
      "Loss: 0.32343806989549195\n",
      "Question: иди ко мне домой  \n",
      " Answer: а как?\n",
      "Loss: 0.40653632443398235\n",
      "Question: что такое счастье, на твой взгляд? \n",
      " Answer: для меня счастье - это состояние удз них \n",
      "Loss: 0.23840569734282327\n",
      "Question: да, это очень здорово. я также люблю спорт и обожаю играть в волейбол и теннис. \n",
      " Answer: замечательно. я считаю, что участие в спор\n",
      "Loss: 0.25484468030626883\n",
      "Question: кст нам так и не дали 200 рублей \n",
      " Answer: *мне\n",
      "Loss: 0.14785829423926772\n",
      "Question: да, это очень важно. конечно, такие дополнительные возможности требуют дополнительных затрат со стороны школы, но это является важным инвестированием в будущее наших учеников. \n",
      " Answer: в целом, я согласен с тобой.\n",
      "Loss: 0.11703211616782937\n",
      "Question: я, кстати, тоже люблю музыку. я часто слушаю разную музыку, особенно в машине, когда еду на работу. \n",
      " Answer: да, это здорово. я думаю, что увле\n",
      "Loss: 0.10557884555310011\n",
      "Question: да, это очень важно. конечно, такие дополнительные возможности требуют дополнительных затрат со стороны школы, но это является важным инвестированием в будущее наших учеников. \n",
      " Answer: в целом, я согласен с тобой.\n",
      "Loss: 0.18464974674512633\n",
      "Question: существует ли свободная воля? \n",
      " Answer: я думаю, что есть некоторый уровень свобод\n",
      "Loss: 0.07877270625554957\n",
      "Question: я, кстати, тоже люблю музыку. я часто слушаю разную музыку, особенно в машине, когда еду на работу. \n",
      " Answer: да, для меня музыка - как альтерна\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[53], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train(\u001b[39m30\u001b[39;49m, model, \u001b[39m1\u001b[39;49m)\n",
      "Cell \u001b[1;32mIn[52], line 7\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(epoches, model, batch_size)\u001b[0m\n\u001b[0;32m      5\u001b[0m loss_avg \u001b[39m=\u001b[39m[]\n\u001b[0;32m      6\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epoches):\n\u001b[1;32m----> 7\u001b[0m     \u001b[39mfor\u001b[39;00m target,train \u001b[39min\u001b[39;00m get_batch(dataset):\n\u001b[0;32m      8\u001b[0m         model\u001b[39m.\u001b[39mtrain()\n\u001b[0;32m     10\u001b[0m         hidden \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39minit_hidden(batch_size)\n",
      "Cell \u001b[1;32mIn[51], line 7\u001b[0m, in \u001b[0;36mget_batch\u001b[1;34m(dataset)\u001b[0m\n\u001b[0;32m      4\u001b[0m target \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(tokenizer\u001b[39m.\u001b[39mtokenize(qa\u001b[39m.\u001b[39manswer))\u001b[39m+\u001b[39m[tokens\u001b[39m.\u001b[39mcount()]\n\u001b[0;32m      5\u001b[0m test \u001b[39m=\u001b[39m question_idx\u001b[39m+\u001b[39mtarget[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m----> 7\u001b[0m target \u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39;49mLongTensor(target)\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m      8\u001b[0m test \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mLongTensor(test)\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m      9\u001b[0m \u001b[39myield\u001b[39;00m target,test\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(30, model, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'звездные войны\". а у тебя?'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quest = input().lower()\n",
    "evaluate(model,quest,35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model,\"data.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"data.pkl\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 4.0638e-44,  8.4078e-45,  8.4078e-45, -1.4013e-45, -8.4078e-45,\n",
       "           7.0065e-45],\n",
       "         [ 4.0638e-44,  8.4078e-45,  8.4078e-45, -1.4013e-45, -8.4078e-45,\n",
       "           7.0065e-45],\n",
       "         [ 4.0638e-44,  8.4078e-45,  8.4078e-45, -1.4013e-45, -8.4078e-45,\n",
       "           7.0065e-45],\n",
       "         [ 4.0638e-44,  8.4078e-45,  8.4078e-45, -1.4013e-45, -8.4078e-45,\n",
       "           7.0065e-45],\n",
       "         [ 4.0638e-44,  8.4078e-45,  8.4078e-45, -1.4013e-45, -8.4078e-45,\n",
       "           7.0065e-45]], grad_fn=<SqueezeBackward1>),\n",
       " tensor([[-0.0321,  0.0983,  0.1123, -0.2716,  0.2598, -0.0007],\n",
       "         [-0.0276,  0.0937,  0.0941, -0.2640,  0.2666, -0.0003],\n",
       "         [-0.0249,  0.0907,  0.0846, -0.2574,  0.2705,  0.0070],\n",
       "         [-0.0251,  0.0860,  0.0800, -0.2522,  0.2768,  0.0137],\n",
       "         [-0.0288,  0.0798,  0.0762, -0.2562,  0.2790,  0.0122]],\n",
       "        grad_fn=<AddmmBackward0>),\n",
       " tensor([[-1.4013e-45,  1.4013e-45,  1.4013e-45,  0.0000e+00, -2.8026e-45,\n",
       "          -0.0000e+00],\n",
       "         [-1.4013e-45,  1.4013e-45,  1.4013e-45,  0.0000e+00, -2.8026e-45,\n",
       "          -0.0000e+00],\n",
       "         [-1.4013e-45,  1.4013e-45,  1.4013e-45,  0.0000e+00, -2.8026e-45,\n",
       "           0.0000e+00],\n",
       "         [-1.4013e-45,  1.4013e-45,  0.0000e+00,  0.0000e+00, -2.8026e-45,\n",
       "           0.0000e+00],\n",
       "         [-1.4013e-45,  0.0000e+00,  0.0000e+00,  0.0000e+00, -2.8026e-45,\n",
       "           0.0000e+00]], grad_fn=<MulBackward0>))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "\n",
    "class abracadabra(nn.Module):\n",
    "    def __init__(self,size):\n",
    "        super(abracadabra,self).__init__()\n",
    "        self.size = size\n",
    "\n",
    "        self.embeding = nn.Embedding(size,10)\n",
    "        self.l1 = nn.Linear(10,size)\n",
    "        self.attention = nn.MultiheadAttention(size,2)\n",
    "        self.lstm = nn.LSTM(size,10,2)\n",
    "        self.l2 = nn.Linear(10,size)\n",
    "        \n",
    "        \n",
    "    def forward(self,x,k,v,hidden=None):\n",
    "        x = self.embeding(x)\n",
    "        x = self.l1(x)\n",
    "        a,b = self.attention(x.view(-1,self.size),k.view(-1,self.size),v.view(-1,self.size))#a - attn output b - attn_wheights\n",
    "        out,hidden = self.lstm(x,hidden)\n",
    "        out = self.l2(out)\n",
    "        sumt = a*out\n",
    "        return a,out,sumt\n",
    "    \n",
    "model = abracadabra(6)\n",
    "k = torch.Tensor(6)\n",
    "v = torch.Tensor(6)\n",
    "x=torch.LongTensor([1,2,3,4,5])\n",
    "model(x,k,v)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
