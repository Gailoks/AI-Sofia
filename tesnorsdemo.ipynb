{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create simple tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5])\n",
      "tensor([1, 2, 3, 4, 5])\n"
     ]
    }
   ],
   "source": [
    "tensor = LongTensor([1, 2, 3, 4, 5])\n",
    "\n",
    "print(tensor.size())\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create multidimensional tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1,  2],\n",
      "         [ 2,  4],\n",
      "         [ 3,  9],\n",
      "         [ 4, 10]]])\n",
      "torch.Size([1, 4, 2])\n"
     ]
    }
   ],
   "source": [
    "tensor = LongTensor([\n",
    "    [[1, 2],\n",
    "     [2, 4],\n",
    "     [3, 9],\n",
    "     [4, 10]]\n",
    "])\n",
    "\n",
    "# In front projection\n",
    "# # -> 1d\n",
    "# |   1\n",
    "# 2d  2\n",
    "#     3\n",
    "#     4\n",
    "#\n",
    "# In right side projection\n",
    "# # -> 3d\n",
    "# |   1  2\n",
    "# 2d  2  4\n",
    "#     3  9\n",
    "#     4  10\n",
    "\n",
    "print(tensor)\n",
    "print(tensor.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "view() operation \"casts\" tensor to target dimensions, it ignores current tensor structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1,  2,  2,  4,  3,  9,  4, 10])\n",
      "torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "tensor = LongTensor([[[1, 2], [2, 4], [3, 9], [4, 10]]])\n",
    "\n",
    "tensor = tensor.view(8) # transform to 1-d linear, where 8 - excpted size in first dim\n",
    "\n",
    "print(tensor)\n",
    "print(tensor.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1,  2],\n",
      "        [ 2,  4],\n",
      "        [ 3,  9],\n",
      "        [ 4, 10]])\n",
      "torch.Size([4, 2])\n"
     ]
    }
   ],
   "source": [
    "tensor = LongTensor([[[1, 2], [2, 4], [3, 9], [4, 10]]])\n",
    "\n",
    "tensor = tensor.view(4, 2) # transform to 2-d linear, where 4 - excpted size in first dim, 2 - in second dim\n",
    "\n",
    "print(tensor)\n",
    "print(tensor.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "view() also supports -1 value for dimension size, it means that the size in this dimensions will be calculated using current tensor elements count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1,  2],\n",
      "        [ 2,  4],\n",
      "        [ 3,  9],\n",
      "        [ 4, 10]])\n",
      "torch.Size([4, 2])\n",
      "tensor([[ 2,  3,  1,  2],\n",
      "        [ 8,  1,  2,  4],\n",
      "        [ 1,  1,  3,  9],\n",
      "        [ 0,  8,  4, 10]])\n",
      "torch.Size([4, 4])\n"
     ]
    }
   ],
   "source": [
    "tensor = LongTensor([[[1, 2], [2, 4], [3, 9], [4, 10]]])\n",
    "\n",
    "tensor = tensor.view(4, -1) # transform to 2-d linear, where 4 - excpted size in first dim, -1 determines any size in second dim\n",
    "\n",
    "print(tensor)\n",
    "print(tensor.size())\n",
    "\n",
    "# Other example\n",
    "\n",
    "tensor = LongTensor([[[[2, 3, 1, 2], [8, 1, 2, 4]], [[1, 1, 3, 9], [0, 8, 4, 10]]]])\n",
    "\n",
    "tensor = tensor.view(4, -1) # transform to 2-d linear, where 4 - excpted size in first dim, -1 determines any size in second dim\n",
    "\n",
    "print(tensor)\n",
    "print(tensor.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "permute() operation \"swaps\" dimensions in tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4],\n",
      "        [5, 6]])\n",
      "torch.Size([3, 2])\n",
      "tensor([[1, 3, 5],\n",
      "        [2, 4, 6]])\n",
      "torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "tensor = LongTensor([[1, 2], [3, 4], [5, 6]])\n",
    "\n",
    "print(tensor)\n",
    "print(tensor.size())\n",
    "\n",
    "# # -> 1d\n",
    "# |   1  2\n",
    "# 2d  3  4\n",
    "#     5  6\n",
    "\n",
    "tensor = tensor.permute((1, 0))\n",
    "\n",
    "# # -> 1d (old 2d)\n",
    "# |    \n",
    "# 2d    1  3  5\n",
    "# old   2  4  6\n",
    "# 1d\n",
    "\n",
    "print(tensor)\n",
    "print(tensor.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1,  2],\n",
      "         [ 3,  4],\n",
      "         [ 5,  6]],\n",
      "\n",
      "        [[-1, -2],\n",
      "         [-3, -4],\n",
      "         [-5, -6]]])\n",
      "torch.Size([2, 3, 2])\n",
      "tensor([[[ 1,  2],\n",
      "         [-1, -2]],\n",
      "\n",
      "        [[ 3,  4],\n",
      "         [-3, -4]],\n",
      "\n",
      "        [[ 5,  6],\n",
      "         [-5, -6]]])\n",
      "torch.Size([3, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "tensor = LongTensor([[[1, 2], [3, 4], [5, 6]], [[-1, -2], [-3, -4], [-5, -6]]])\n",
    "\n",
    "print(tensor)\n",
    "print(tensor.size())\n",
    "\n",
    "tensor = tensor.permute((1, 0, 2))\n",
    "\n",
    "print(tensor)\n",
    "print(tensor.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "permute is more recommended to ... permute! tensor dimensions, but it can't be used anywhere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "permute(sparse_coo): number of dimensions in the tensor input does not match the length of the desired ordering of dimensions i.e. input.dim() = 1 is not equal to len(dims) = 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m tensor \u001b[39m=\u001b[39m LongTensor([\u001b[39m1\u001b[39;49m, \u001b[39m2\u001b[39;49m, \u001b[39m3\u001b[39;49m, \u001b[39m4\u001b[39;49m])\u001b[39m.\u001b[39;49mpermute((\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, \u001b[39m0\u001b[39;49m)) \u001b[39m# can't create NEW dimensions\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: permute(sparse_coo): number of dimensions in the tensor input does not match the length of the desired ordering of dimensions i.e. input.dim() = 1 is not equal to len(dims) = 2"
     ]
    }
   ],
   "source": [
    "tensor = LongTensor([1, 2, 3, 4]).permute((-1, 0)) # can't create NEW dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.cat() concatenates the given sequence of tensors in the some dimension. All tensors must have same shape (except target dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3., 4., 5., 6.])\n",
      "torch.Size([6])\n",
      "tensor([-1., -2., -3., -4.])\n",
      "torch.Size([4])\n",
      "tensor([ 1.,  2.,  3.,  4.,  5.,  6., -1., -2., -3., -4.])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "# Not equal size in first dim\n",
    "tensor1 = Tensor([1, 2, 3, 4, 5, 6])\n",
    "tensor2 = Tensor([-1, -2, -3, -4])\n",
    "\n",
    "print(tensor1)\n",
    "print(tensor1.size())\n",
    "print(tensor2)\n",
    "print(tensor2.size())\n",
    "\n",
    "tensor = cat((tensor1, tensor2), 0) # linear concatenation\n",
    "print(tensor)\n",
    "print(tensor.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenation to new dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.],\n",
      "        [2.],\n",
      "        [3.],\n",
      "        [4.]])\n",
      "torch.Size([4, 1])\n",
      "tensor([[-1.],\n",
      "        [-2.],\n",
      "        [-3.],\n",
      "        [-4.]])\n",
      "torch.Size([4, 1])\n",
      "tensor([[ 1., -1.],\n",
      "        [ 2., -2.],\n",
      "        [ 3., -3.],\n",
      "        [ 4., -4.]])\n",
      "torch.Size([4, 2])\n"
     ]
    }
   ],
   "source": [
    "# Not equal size in first dim\n",
    "tensor1 = Tensor([1, 2, 3, 4]).view(-1, 1) # Transform to pseudo 2d\n",
    "tensor2 = Tensor([-1, -2, -3, -4]).view(-1, 1) # Transform to pseudo 2d\n",
    "\n",
    "print(tensor1)\n",
    "print(tensor1.size())\n",
    "print(tensor2)\n",
    "print(tensor2.size())\n",
    "\n",
    "tensor = cat((tensor1, tensor2), 1) # linear concatenation\n",
    "\n",
    "print(tensor)\n",
    "print(tensor.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lifehacks show!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extend tensor to new dim in common case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2, 1])\n",
      "torch.Size([3, 2, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "tensor = Tensor([[[1], [2]], [[1], [2]], [[1], [2]]])\n",
    "\n",
    "print(tensor.size())\n",
    "\n",
    "tensor = tensor.view(*tensor.size(), 1)\n",
    "\n",
    "print(tensor.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "========================================================================================================================================================================\n",
    "\n",
    "***Neural Networks***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Simple linear module**\n",
    "[documentation](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html?highlight=linear#torch.nn.Linear)\n",
    "\n",
    "Input: \n",
    "(∗, Hin) where ∗ means any number of dimensions including none\n",
    "\n",
    "Output: (∗, Hout) where all but the last dimension are the same shape as the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3., 4., 5.])\n",
      "torch.Size([5])\n",
      "torch.Size([15])\n"
     ]
    }
   ],
   "source": [
    "linear = Linear(5, 15)\n",
    "\n",
    "tensor = Tensor([1, 2, 3, 4, 5])\n",
    "\n",
    "print(tensor)\n",
    "print(tensor.size())\n",
    "\n",
    "tensor = linear(tensor)\n",
    "\n",
    "print(tensor.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.],\n",
      "        [2.],\n",
      "        [3.],\n",
      "        [4.],\n",
      "        [5.]])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 2])\n"
     ]
    }
   ],
   "source": [
    "linear = Linear(1, 2)\n",
    "\n",
    "tensor = Tensor([1, 2, 3, 4, 5]).view(-1, 1)\n",
    "\n",
    "print(tensor)\n",
    "print(tensor.size())\n",
    "\n",
    "tensor = linear(tensor)\n",
    "\n",
    "print(tensor.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear module applies to LAST DIMENSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LSTM module**\n",
    "[documentation](https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html#torch.nn.LSTM)\n",
    "\n",
    "num_layers – Number of recurrent layers. E.g., setting num_layers=2 would mean stacking two LSTMs together to form a stacked LSTM, with the second LSTM taking in outputs of the first LSTM and computing the final results. Default: 1\n",
    "\n",
    "Inputs: input or pair (input, (h_0, c_0))\n",
    "\n",
    "input: <- our input for recurrent nn module\n",
    "* unbatched: (Len, Hin) \n",
    "* batched (batch_first=False): (Len, Batch, Hin)\n",
    "* batched (batch_first=True): (Batch, Len, Hin)\n",
    "\n",
    "h_0: (num_layers, Hhid) or (num_layers, Batch, Hhid) <- initial hidden state\n",
    "\n",
    "c_0: (num_layers, Hhid) or (num_layers, Batch, Hhid) <- initial cell state\n",
    "\n",
    "Outputs: pair (output, (h_Len, c_Len))\n",
    "\n",
    "output:\n",
    "* unbatched: (Len, Hhid) \n",
    "* batched (batch_first=False): (Len, Batch, Hhid)\n",
    "* batched (batch_first=True): (Batch, Len, Hhid)\n",
    "\n",
    "h_Len: (num_layers, Hhid) or (num_layers, Batch, Hhid) <- last hidden state\n",
    "\n",
    "c_Len: (num_layers, Hhid) or (num_layers, Batch, Hhid) <- last cell state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.],\n",
      "         [-1.]],\n",
      "\n",
      "        [[ 2.],\n",
      "         [-2.]],\n",
      "\n",
      "        [[ 3.],\n",
      "         [-3.]],\n",
      "\n",
      "        [[ 4.],\n",
      "         [-4.]]])\n",
      "main input: torch.Size([4, 2, 1])\n",
      "main output: torch.Size([4, 2, 5])\n",
      "last output el: torch.Size([2, 5])\n",
      "h_Len: torch.Size([3, 2, 5])\n",
      "c_Len: torch.Size([3, 2, 5])\n"
     ]
    }
   ],
   "source": [
    "lstm = LSTM(input_size = 1, hidden_size = 5, num_layers = 3, batch_first = False)\n",
    "\n",
    "# seq len - 4, batch size - 2\n",
    "# positive number - batch 1, negative - batch 2\n",
    "tensor = Tensor([[[1], [2], [3], [4]], [[-1], [-2], [-3], [-4]]]).permute(1, 0, 2)\n",
    "\n",
    "print(tensor)\n",
    "print(\"main input: \" + str(tensor.size()))\n",
    "\n",
    "tensor, (h, c) = lstm(tensor)\n",
    "\n",
    "print(\"main output: \" + str(tensor.size()))\n",
    "print(\"last output el: \" + str(tensor[-1].size()))\n",
    "print(\"h_Len: \" + str(h.size()))\n",
    "print(\"c_Len: \" + str(c.size()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Embedding module** [documentation](https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html#torch.nn.Embedding)\n",
    "\n",
    "Input: (*) as LongTensor or IntTensor, every element in [0, num_embeddings)\n",
    "\n",
    "Output: (*, embeding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3, 4],\n",
      "        [5, 6, 7, 8]])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 4, 2])\n"
     ]
    }
   ],
   "source": [
    "embedding = Embedding(num_embeddings = 10, embedding_dim = 2)\n",
    "\n",
    "tensor = LongTensor([[1, 2, 3, 4], [5, 6, 7, 8]])\n",
    "\n",
    "print(tensor)\n",
    "print(tensor.size())\n",
    "\n",
    "tensor = embedding(tensor)\n",
    "\n",
    "print(tensor.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embedding \"extrudes\" every element to new dim, extruding len equals embedding_dim"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
